logging:
  entity: 
  project: "ddpm-flax-flower102"
  job_type: "training"
  name:
  log_train: true
  log_sample: true
  log_model: true
  save_checkpoint: true

training:
  num_train_steps: 1000
  log_every_steps: 10
  loss_type: 'huber'
  half_precision: false
  save_and_sample_every: 1000
  num_sample: 64

ema:
  beta: 0.995
  update_every: 10
  update_after_step: 100
  inv_gamma: 1.0
  power: 2/3
  min_value: 0.0

ddpm:
  beta_schedule: 'cosine'
  timesteps: 1000
  p2_loss_weight_gamma: 0. # p2 loss weight, from https://arxiv.org/abs/2204.00227 - 0 is equivalent to weight of 1 across time - 1. is recommended
  p2_loss_weight_k: 1
  self_condition: false # not tested yet
  pred_x0: false # by default, the model will predict noise, if True predict x0

data:
  hf_dataset: 'nelorth/oxford-flowers'
  batch_size: 8 
  cache: true
  image_size: 64
  channels: 3

model:
  dim: 32
  dim_mults: [1, 2, 4, 8]

optim:
  optimizer: 'Adam'
  lr: 2e-4
  beta1: 0.9
  beta2: 0.99
  eps: 1e-8

seed: 42
